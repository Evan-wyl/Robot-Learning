# Foundation Model

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re) [![MIT License](https://img.shields.io/badge/license-MIT-green.svg)](https://opensource.org/licenses/MIT) [![LICENSE](https://img.shields.io/badge/license-Anti%20996-blue.svg)](https://github.com/996icu/996.ICU/blob/master/LICENSE)

Papers, codes, datasets, tasks, applications, tutorials.

**Widely used by top conferences and journals:**

- Top Conferences: [[ICML MFM-EAI Workshop](https://icml-mfm-eai.github.io/)]



## 0.Survey

[2021] [On the Opportunities and Risks of Foundation Models](https://arxiv.org/abs/2108.07258)

[2023] [Large language models for humanâ€“robot interaction: A review](https://www.sciencedirect.com/science/article/pii/S2667379723000451)

[2023] [Foundation Models in Robotics: Applications, Challenges, and the Future](https://arxiv.org/abs/2312.07843)

[2023] [Robot Learning in the Era of Foundation Models: A Survey](https://arxiv.org/abs/2311.14379)

[2023] [Toward General-Purpose Robots via Foundation Models: A Survey and Meta-Analysis](https://arxiv.org/abs/2312.08782)

[2023] [Foundation Models for Decision Making: Problems, Methods, and Opportunities](https://arxiv.org/abs/2303.04129)

[2024] [Large Language Models for Robotics: Opportunities, Challenges, and Perspectives](https://arxiv.org/abs/2401.04334)

[2024] [Real-World Robot Applications of Foundation Models: A Review](https://arxiv.org/abs/2402.05741)

[2024] [A Survey on Vision-Language-Action Models for Embodied AI](https://arxiv.org/abs/2405.14093)

[2024] [Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI](https://arxiv.org/abs/2407.06886)

:speaker: ***If you would like some specific areas' survey, such as  multimodal large model, large language model, and etc, please click related links in part one.***



## 1.Research Areas and Papers

:speaker: ***There are just some pretty papers for beginners and interested figures.***

- [Embodied AI](https://github.com/Evan-wyl/Robot-Learning/blob/master/fm/papers/embodied-ai.md)
- [Generative AI](https://github.com/Evan-wyl/Robot-Learning/blob/master/fm/papers/generative-ai.md)
- [High-Level Task Planning](https://github.com/Evan-wyl/Robot-Learning/blob/master/fm/papers/high-level-task-planning.md)
- [Language Image Goal Conditioned Value Learning](https://github.com/Evan-wyl/Robot-Learning/blob/master/fm/papers/language-image-goal-conditioned-value-learning.md)
- [LLM-Based Code Generation](https://github.com/Evan-wyl/Robot-Learning/blob/master/fm/papers/llm-based-code-generation.md)
- [Large Language Model](https://github.com/Evan-wyl/Robot-Learning/blob/master/fm/papers/llm.md)
- [Multi-Modal Large Model](https://github.com/Evan-wyl/Robot-Learning/blob/master/fm/papers/multi-modal-lagre-model.md)
- [Multimodal Machine Learning](https://github.com/Evan-wyl/Robot-Learning/blob/master/fm/papers/multimodal-machine-learning.md)
- [Navigation](https://github.com/Evan-wyl/Robot-Learning/blob/master/fm/papers/navigation.md)
- [Robotic Transformer](https://github.com/Evan-wyl/Robot-Learning/blob/master/fm/papers/robotic-transformer.md)
- [Robot Policy Learning](https://github.com/Evan-wyl/Robot-Learning/blob/master/fm/papers/robot-policy-learning.md)
- [Vision Language Action](https://github.com/Evan-wyl/Robot-Learning/blob/master/fm/papers/vision-language-action.md)
- [Vision Audio Tactile Action](https://github.com/Evan-wyl/Robot-Learning/blob/master/fm/papers/vision-audio-tactile.md)
- [Video Action](https://github.com/Evan-wyl/Robot-Learning/blob/master/fm/papers/video-action.md)
- [Vision Foundation Model](https://github.com/Evan-wyl/Robot-Learning/blob/master/fm/papers/vision-foundation-model.md)
- [World Model and its Application](https://github.com/Evan-wyl/Robot-Learning/blob/master/fm/papers/world-models)



## 2.Datasets and Benchmarks

Please see [Here](https://github.com/Evan-wyl/Robot-Learning/tree/master/fm/data) for the popular robot learning **datasets, simulator and benchmark** results.



## 3.Relevant Resources

Please see [HERE](https://github.com/Evan-wyl/Robot-Learning/tree/master/resources.md) for some awesome relevant resources, such as

- Awesome Repository, including Large Model inference and evaluation.

------

***Copyright notice***

> ***[Notes]This Github repo can be used by following the corresponding licenses. I want to emphasis that it may contain some PDFs or thesis, which were downloaded by me and can only be used for academic purposes. The copyrights of these materials are owned by corresponding publishers or organizations. All this are for better adademic research. If any of the authors or publishers have concerns, please contact me to delete or replace them.***