## Fine-Tuning

### Large Language Model

[2023] [Instruction Tuning with GPT-4](https://arxiv.org/abs/2304.03277)

[2023] [Symbol tuning improves in-context learning in language models](https://arxiv.org/abs/2305.08298)

[2024] [PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models](https://arxiv.org/abs/2404.02948)

#### LoRA

[2021] [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)

[2023] [Punica: Multi-Tenant LoRA Serving](https://arxiv.org/abs/2310.18547)

[2023] [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314)

[2024] [LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report](https://arxiv.org/abs/2405.00732)

[2024] [LoRA Learns Less and Forgets Less](https://arxiv.org/abs/2405.09673)

[2024] [LoRA+: Efficient Low Rank Adaptation of Large Models](https://arxiv.org/abs/2402.12354)



### Multi-Modal Large Model

[2023] [Tuning LayerNorm in Attention: Towards Efficient Multi-Modal LLM Finetuning](https://arxiv.org/abs/2312.11420)



### Vision Language Model

[2022] [Visual Prompt Tuning](https://arxiv.org/abs/2203.12119)

[2023] [Visual Instruction Tuning](https://arxiv.org/abs/2304.08485)