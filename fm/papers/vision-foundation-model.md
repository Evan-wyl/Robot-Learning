## Vision Foundation Model

[2023] [Segment Anything](https://arxiv.org/abs/2304.02643)

[2024] [Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data](https://arxiv.org/abs/2401.10891)

[2024] [SAM 2: Segment Anything in Images and Videos](https://ai.meta.com/sam2/)

[2024] [Theia: Distilling Diverse Vision Foundation Models for Robot Learning](https://arxiv.org/abs/2407.20179)



### Survey

[2024] [Parameter-Efficient Fine-Tuning for Pre-Trained Vision Models: A Survey](https://arxiv.org/abs/2402.02242)